{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How Has the Pandemic Affected Trail Use in Seattle Parks?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For my first Python project, I was curious how the pandemic was affecting transportation, as I am a transportation planner. I have gone out to exercise every day during the stay at home orders, and have observed many others doing the same, particularly at big city parks, like Myrtle Edwards. The City took notice and closed down some parks temporarily that were getting too crowded to allow for social distancing. I wondered if people were more likely to be in parks these days given that there are so few other places to be. I found a dataset from the Seattle Department of Transportation on bicycle and pedestrian counts from 2014-2020 at a specific point at Myrtle Edwards Park: https://data.seattle.gov/Transportation/Elliott-Bay-Trail-in-Myrtle-Edwards-Park-Bicycle-a/4qej-qvrz. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, I import libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: You are using pip version 20.1; however, version 20.3.3 is available.\n",
      "You should consider upgrading via the '/Library/Frameworks/Python.framework/Versions/3.7/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install ipywidgets>=7.5\n",
    "import pandas as pd\n",
    "import plotly\n",
    "plotly.offline.init_notebook_mode(connected=True)\n",
    "import plotly.graph_objects as go\n",
    "import time\n",
    "import datetime\n",
    "import math\n",
    "import requests\n",
    "from sodapy import Socrata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bike/ped count dataset\n",
    "client = Socrata(\"data.seattle.gov\",\n",
    "                  '6uBQfIU2lNztoWvnnrDRJvTLH')\n",
    "\n",
    "# returned as JSON from API / converted to Python list of dictionaries by sodapy.\n",
    "results = client.get(\"4qej-qvrz\", limit = 100000)\n",
    "\n",
    "# Convert to pandas DataFrame\n",
    "results_df = pd.DataFrame.from_records(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>eilliott_bay_trail_in_myrtle_edwards_park_total</th>\n",
       "      <th>ped_north</th>\n",
       "      <th>ped_south</th>\n",
       "      <th>bike_north</th>\n",
       "      <th>bike_south</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-06-01T00:00:00.000</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-06-01</td>\n",
       "      <td>00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-06-01T01:00:00.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-06-01</td>\n",
       "      <td>01:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-06-01T02:00:00.000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-06-01</td>\n",
       "      <td>02:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-06-01T03:00:00.000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-06-01</td>\n",
       "      <td>03:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-06-01T04:00:00.000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-06-01</td>\n",
       "      <td>04:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      date eilliott_bay_trail_in_myrtle_edwards_park_total  \\\n",
       "0  2020-06-01T00:00:00.000                                               5   \n",
       "1  2020-06-01T01:00:00.000                                               0   \n",
       "2  2020-06-01T02:00:00.000                                               1   \n",
       "3  2020-06-01T03:00:00.000                                               1   \n",
       "4  2020-06-01T04:00:00.000                                               1   \n",
       "\n",
       "  ped_north ped_south bike_north bike_south        Date      Time  \n",
       "0         2         1          1          1  2020-06-01  00:00:00  \n",
       "1         0         0          0          0  2020-06-01  01:00:00  \n",
       "2         0         0          1          0  2020-06-01  02:00:00  \n",
       "3         1         0          0          0  2020-06-01  03:00:00  \n",
       "4         0         0          1          0  2020-06-01  04:00:00  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#convert the datetime field in the \"date\" column to something more readable and separate date and time.\n",
    "results_df['Date'] = pd.to_datetime(results_df['date']).dt.date \n",
    "results_df['Time'] = pd.to_datetime(results_df['date']).dt.time \n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp_Date</th>\n",
       "      <th>Total</th>\n",
       "      <th>ped_north</th>\n",
       "      <th>ped_south</th>\n",
       "      <th>bike_north</th>\n",
       "      <th>bike_south</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Day of Week</th>\n",
       "      <th>Month</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-06-01T00:00:00.000</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-06-01</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>Monday</td>\n",
       "      <td>June</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-06-01T01:00:00.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-06-01</td>\n",
       "      <td>01:00:00</td>\n",
       "      <td>Monday</td>\n",
       "      <td>June</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-06-01T02:00:00.000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-06-01</td>\n",
       "      <td>02:00:00</td>\n",
       "      <td>Monday</td>\n",
       "      <td>June</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-06-01T03:00:00.000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-06-01</td>\n",
       "      <td>03:00:00</td>\n",
       "      <td>Monday</td>\n",
       "      <td>June</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-06-01T04:00:00.000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-06-01</td>\n",
       "      <td>04:00:00</td>\n",
       "      <td>Monday</td>\n",
       "      <td>June</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Timestamp_Date Total ped_north ped_south bike_north bike_south  \\\n",
       "0  2020-06-01T00:00:00.000     5         2         1          1          1   \n",
       "1  2020-06-01T01:00:00.000     0         0         0          0          0   \n",
       "2  2020-06-01T02:00:00.000     1         0         0          1          0   \n",
       "3  2020-06-01T03:00:00.000     1         1         0          0          0   \n",
       "4  2020-06-01T04:00:00.000     1         0         0          1          0   \n",
       "\n",
       "         Date      Time Day of Week Month  Year  \n",
       "0  2020-06-01  00:00:00      Monday  June  2020  \n",
       "1  2020-06-01  01:00:00      Monday  June  2020  \n",
       "2  2020-06-01  02:00:00      Monday  June  2020  \n",
       "3  2020-06-01  03:00:00      Monday  June  2020  \n",
       "4  2020-06-01  04:00:00      Monday  June  2020  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#rename columns and add columns to help with data analysis.\n",
    "clean_df = results_df.rename(columns={\"date\": \"Timestamp_Date\", \"eilliott_bay_trail_in_myrtle_edwards_park_total\": \"Total\"})\n",
    "clean_df['Day of Week'] = pd.DatetimeIndex(clean_df['Date']).day_name() # week day name\n",
    "clean_df['Month'] = pd.DatetimeIndex(clean_df['Date']).month_name() # month name\n",
    "clean_df['Year'] = pd.DatetimeIndex(clean_df['Timestamp_Date']).year # year name\n",
    "clean_df.head()\n",
    "\n",
    "#clean_df['Week Day'] = clean_df['Timestamp_Date'].dt.day_name()\n",
    "#.dt requires a datetime object, not a series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "APIrecords = clean_df.to_dict('records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61368"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So ```APIrecords``` is a list of dictionaries. Each dictionary represents one hour's worth of data and thus each dictionary has the same keys and different values. There are over 56,000 records in this dataset as of May 2020. As I play around with different functions, I need a quick way to select a subset of records so that every function doesn't iterate through the whole thing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I create the below ```testlist``` to give myself a small section of the dataset to try out functions on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Timestamp_Date': '2020-06-01T00:00:00.000',\n",
       "  'Total': '5',\n",
       "  'ped_north': '2',\n",
       "  'ped_south': '1',\n",
       "  'bike_north': '1',\n",
       "  'bike_south': '1',\n",
       "  'Date': datetime.date(2020, 6, 1),\n",
       "  'Time': datetime.time(0, 0),\n",
       "  'Day of Week': 'Monday',\n",
       "  'Month': 'June',\n",
       "  'Year': 2020},\n",
       " {'Timestamp_Date': '2020-06-01T01:00:00.000',\n",
       "  'Total': '0',\n",
       "  'ped_north': '0',\n",
       "  'ped_south': '0',\n",
       "  'bike_north': '0',\n",
       "  'bike_south': '0',\n",
       "  'Date': datetime.date(2020, 6, 1),\n",
       "  'Time': datetime.time(1, 0),\n",
       "  'Day of Week': 'Monday',\n",
       "  'Month': 'June',\n",
       "  'Year': 2020},\n",
       " {'Timestamp_Date': '2020-06-01T02:00:00.000',\n",
       "  'Total': '1',\n",
       "  'ped_north': '0',\n",
       "  'ped_south': '0',\n",
       "  'bike_north': '1',\n",
       "  'bike_south': '0',\n",
       "  'Date': datetime.date(2020, 6, 1),\n",
       "  'Time': datetime.time(2, 0),\n",
       "  'Day of Week': 'Monday',\n",
       "  'Month': 'June',\n",
       "  'Year': 2020},\n",
       " {'Timestamp_Date': '2020-06-01T03:00:00.000',\n",
       "  'Total': '1',\n",
       "  'ped_north': '1',\n",
       "  'ped_south': '0',\n",
       "  'bike_north': '0',\n",
       "  'bike_south': '0',\n",
       "  'Date': datetime.date(2020, 6, 1),\n",
       "  'Time': datetime.time(3, 0),\n",
       "  'Day of Week': 'Monday',\n",
       "  'Month': 'June',\n",
       "  'Year': 2020},\n",
       " {'Timestamp_Date': '2020-06-01T04:00:00.000',\n",
       "  'Total': '1',\n",
       "  'ped_north': '0',\n",
       "  'ped_south': '0',\n",
       "  'bike_north': '1',\n",
       "  'bike_south': '0',\n",
       "  'Date': datetime.date(2020, 6, 1),\n",
       "  'Time': datetime.time(4, 0),\n",
       "  'Day of Week': 'Monday',\n",
       "  'Month': 'June',\n",
       "  'Year': 2020}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testlist = APIrecords[:5]\n",
    "testlist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating Functions to Prepare the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timestamp(mmddyyyy):\n",
    "    return pd.to_datetime(mmddyyyy)\n",
    "\n",
    "def hourlycounts(date): #date must be entered as 'mm/dd/yy', including quotes\n",
    "    y_values=[]\n",
    "    date_filtered = list(record for record in APIrecords if record['Date']==timestamp(date))\n",
    "    list(map(lambda record: y_values.append(record['Total']), date_filtered))\n",
    "    return y_values\n",
    "# can check by running hourlycounts('3/14/20')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If I want to be able to create graphs with time or date as an independent variable, I need to be able to generate a list of all the values associated with a specific key in the list of dictionaries. Below, I create a function and test it out on ```testlist```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Monday', 'Monday', 'Monday', 'Monday', 'Monday']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def list_from_dictionary(dictlist, key):\n",
    "    return [sub[key] for sub in dictlist]\n",
    "list_from_dictionary(testlist, 'Day of Week')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying this function out on ```testlist``` confirms that it would not filter out duplicates, and if I run this on the whole dataset it would return 54,000 items, which I don't want. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create a list of all the values for a given key, without duplicates, I need a new function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Monday']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#generate list of all unique values in a given column in the dataset. Use to generate x values for graphs and in for loops.\n",
    "def unique(recordlist, key):\n",
    "    new_list=[]\n",
    "    list1 = list_from_dictionary(recordlist, key)\n",
    "    list_set = set(list1)\n",
    "    unique_list = list(list_set)\n",
    "    for x in unique_list:\n",
    "        new_list.append(x)\n",
    "    return new_list\n",
    "unique(testlist, 'Day of Week')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I apply this to the 'Time' key, as I plan to use hour of day as an x-value for my initial graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "alltimes = sorted(unique(APIrecords, 'Time'))\n",
    "#alltimes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I want to know how April 2020 overall compares to other years to see if, overall, April 2020 might see different usage than prior years. I'll choose Fridays in April as a way to compare apples to apples across different years.\n",
    "To start with, the function below would give you, for example, the average count at noon for all the Fridays in April 2020. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "246.2"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def hourly_average_by_day(month, year, weekday, hour):\n",
    "    monthly_total = []\n",
    "    matching_records = list(record for record in APIrecords if record['Day of Week']==weekday and record['Month']==month and record['Time']==hour and record['Year']==year)\n",
    "    for record in matching_records:\n",
    "        monthly_total.append(int(record['Total']))\n",
    "    try: \n",
    "        return sum(monthly_total)/len(monthly_total)\n",
    "    except:\n",
    "        return 'error'\n",
    "\n",
    "hourly_average_by_day('March', 2017, 'Friday', datetime.time(17, 0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function above gives me average counts for a specific hour of a specific weekday in the year and month I provide as arguments. Now I want to be able to apply that function to every year all at once, so I can graph it and see a change over time. Maybe people are using the park at different times of day than they used to, and I'm curious how that's changed. The following function applies ```hourly_average_by_day()``` to every year from 2014-2020."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, though, I noticed when looking through the data that no counts were recorded for a large part of 2015; the equipment must have been broken. I don't want to get zeros in my plots, so I'm going to omit 2015 data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[259.0, 277.0, 279.5, 244.25, 196.0, 334.5]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def counts_across_years(month, weekday, hour): #note below how the hour must be formatted.\n",
    "    counts_list=[]\n",
    "    for year in [x for x in range(2014, 2021) if x != 2015]:\n",
    "        count = hourly_average_by_day(month, year, weekday, hour)\n",
    "        counts_list.append(count)\n",
    "    return counts_list\n",
    "\n",
    "counts_across_years('April', 'Friday', datetime.time(12, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2014, 2016, 2017, 2018, 2019, 2020]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allyears=[]\n",
    "for i in [x for x in range(2014, 2021) if x != 2015]:\n",
    "    allyears.append(i)\n",
    "allyears"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Graphing Trail Usage Over Time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time to make my first graph. I will use my ```counts_across_years()``` function to graph how average hourly counts at noon for any given weekday have changed from 2014-2020. I am curious if 2020 will continue past trends or show a departure. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=allyears, y=counts_across_years('April', 'Monday', datetime.time(12, 0)),\n",
    "                    mode='lines',\n",
    "                    name='Mondays, 12-1 pm'))\n",
    "fig.add_trace(go.Scatter(x=allyears, y=counts_across_years('April', 'Tuesday', datetime.time(12, 0)),\n",
    "                    mode='lines',\n",
    "                    name='Tuesdays, 12-1 pm'))\n",
    "fig.add_trace(go.Scatter(x=allyears, y=counts_across_years('April', 'Wednesday', datetime.time(12, 0)),\n",
    "                    mode='lines',\n",
    "                    name='Wednesdays, 12-1 pm'))\n",
    "fig.add_trace(go.Scatter(x=allyears, y=counts_across_years('April', 'Thursday', datetime.time(12, 0)),\n",
    "                    mode='lines',\n",
    "                    name='Thursdays, 12-1 pm'))\n",
    "fig.add_trace(go.Scatter(x=allyears, y=counts_across_years('April', 'Friday', datetime.time(12, 0)),\n",
    "                    mode='lines',\n",
    "                    name='Fridays, 12-1 pm'))\n",
    "fig.update_layout(title='Average Park Activity During Different Days of the Week in April, Lunchtime',\n",
    "                   xaxis_title='Year',\n",
    "                   yaxis_title='Average Bike + Ped Count')\n",
    "#fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data suggests that park usage on any given weekday in April 2020 is higher compared to the same weekday in 2019, except on Tuesdays, but compared to prior years there's no recognizable pattern. This is just the lunch hour though. Will this pattern hold after work hours?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=allyears, y=counts_across_years('April', 'Monday', datetime.time(17, 0)),\n",
    "                    mode='lines',\n",
    "                    name='Mondays, 5-6 pm'))\n",
    "fig.add_trace(go.Scatter(x=allyears, y=counts_across_years('April', 'Tuesday', datetime.time(17, 0)),\n",
    "                    mode='lines',\n",
    "                    name='Tuesdays, 5-6 pm'))\n",
    "fig.add_trace(go.Scatter(x=allyears, y=counts_across_years('April', 'Wednesday', datetime.time(17, 0)),\n",
    "                    mode='lines',\n",
    "                    name='Wednesdays, 5-6 pm'))\n",
    "fig.add_trace(go.Scatter(x=allyears, y=counts_across_years('April', 'Thursday', datetime.time(17, 0)),\n",
    "                    mode='lines',\n",
    "                    name='Thursdays, 5-6 pm'))\n",
    "fig.add_trace(go.Scatter(x=allyears, y=counts_across_years('April', 'Friday', datetime.time(17, 0)),\n",
    "                    mode='lines',\n",
    "                    name='Fridays, 5-6 pm'))\n",
    "fig.add_trace(go.Scatter(x=allyears, y=counts_across_years('April', 'Saturday', datetime.time(17, 0)),\n",
    "                    mode='lines',\n",
    "                    name='Saturdays, 5-6 pm'))\n",
    "\n",
    "fig.update_layout(title='Average Park Activity During Different Days of the Week in March, Evenings',\n",
    "                   xaxis_title='Year',\n",
    "                   yaxis_title='Average Bike + Ped Count')\n",
    "#fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, the same pattern doesn't hold from the 5 to 6 pm hour, at least not every day. While Tuesday and Wednesday afternoons see a steep drop from 2019, Thursday and Fridays see increases. But while in 2019 there was  noticeably higher usage earlier in the week, in 2020 usage is converging on all days except Monday. Perhaps the pandemic has wiped away most of the weekly rhythms that distinguish one weekday from another. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I'd like to get a sense of how usage varies throughout the day. This could help people determine the least crowded time to visit the park, for example. The function below takes a month, year, and weekday (for example, Fridays in March 2020) and returns average counts for each hour: average counts at 10am, average counts at 11am, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[12.25,\n",
       " 4.0,\n",
       " 4.75,\n",
       " 2.25,\n",
       " 8.75,\n",
       " 20.0,\n",
       " 112.75,\n",
       " 204.0,\n",
       " 188.75,\n",
       " 210.5,\n",
       " 241.0,\n",
       " 282.75,\n",
       " 334.5,\n",
       " 371.0,\n",
       " 350.0,\n",
       " 403.75,\n",
       " 436.75,\n",
       " 501.0,\n",
       " 529.0,\n",
       " 342.75,\n",
       " 128.0,\n",
       " 40.5,\n",
       " 29.5,\n",
       " 10.0]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def monthly_average_by_hour(month, year, weekday):\n",
    "    hourly_average=[]\n",
    "    hourlist = sorted(unique(APIrecords, 'Time'))\n",
    "    for hour in hourlist:\n",
    "        hourly_average.append(hourly_average_by_day(month, year, weekday, hour))\n",
    "    return hourly_average\n",
    "monthly_average_by_hour('April', 2020, 'Friday')\n",
    "#it would be best if this were a dictionary so we could ensure keys and values are matched up."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That data looks about right, based on what I've observed on various of my own walks! Usage peaks in late afternoon when people get off work and it is warmer. For now I'm going to apply this function to different years in the dataset to compare trends year over year. But instead of Friday, I'll graph Wednesday, because in transportation terms you get a better picture of people's habits if you choose data in the middle of the week. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=alltimes, y=monthly_average_by_hour('April', 2020, 'Wednesday'),\n",
    "                    mode='lines',\n",
    "                    name='2020'))\n",
    "fig.add_trace(go.Scatter(x=alltimes, y=monthly_average_by_hour('April', 2019, 'Wednesday'),\n",
    "                    mode='lines',\n",
    "                    name='2019'))\n",
    "fig.add_trace(go.Scatter(x=alltimes, y=monthly_average_by_hour('April', 2018, 'Wednesday'),\n",
    "                    mode='lines',\n",
    "                    name='2018'))\n",
    "fig.add_trace(go.Scatter(x=alltimes, y=monthly_average_by_hour('April', 2017, 'Wednesday'),\n",
    "                    mode='lines',\n",
    "                    name='2017'))\n",
    "fig.add_trace(go.Scatter(x=alltimes, y=monthly_average_by_hour('April', 2016, 'Wednesday'),\n",
    "                    mode='lines',\n",
    "                    name='2016'))\n",
    "fig.update_layout(title='Average Hourly Park Activity for Wednesdays in April',\n",
    "                   xaxis_title='Hour of Day',\n",
    "                   yaxis_title='Average Bike + Ped Count')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So activity in April 2020 does not really stand out compared to other years."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we've been looking at April 2020 only as a whole. Let's zoom in on April 2020 by graphing hourly counts for every Friday that month. I posit that counts will creep up week after week, as more and more people begin working from home and looking for ways to get some exercise during and after work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Create figure with secondary y-axis\n",
    "fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "\n",
    "fig.add_trace(go.Scatter(x=alltimes, y=hourlycounts('4/3/2020'),\n",
    "                    mode='lines',\n",
    "                    name='April 3',\n",
    "                    line_color='rgb(40, 246, 212)'),\n",
    "                    secondary_y=False)\n",
    "fig.add_trace(go.Scatter(x=alltimes, y=hourlycounts('4/10/2020'),\n",
    "                    mode='lines',\n",
    "                    name='April 10',\n",
    "                    line_color='rgb(27, 164, 161)'),\n",
    "                    secondary_y=False)\n",
    "fig.add_trace(go.Scatter(x=alltimes, y=hourlycounts('4/17/2020'),\n",
    "                    mode='lines',\n",
    "                    name='April 17',\n",
    "                    line_color='rgb(15, 82, 110)'),\n",
    "                    secondary_y=False)\n",
    "fig.add_trace(go.Scatter(x=alltimes, y=hourlycounts('4/24/2020'),\n",
    "                    mode='lines',\n",
    "                    name='April 24',\n",
    "                    line_color='rgb(3, 1, 60)'),\n",
    "                    secondary_y=False)\n",
    "\n",
    "fig.update_layout(title='Bike and Ped Activity in Myrtle Edwards Park - Fridays During Covid-19 (2020)',\n",
    "                   xaxis_title='Hour of Day',\n",
    "                   yaxis_title='Total Bike + Ped Count')\n",
    "#fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, I was wrong. Bicyle and pedestrian counts seem to vary quite a bit by day, and don't seem to be increasing over time. Could weather be a factor in day to day differences? Let's dig into some more data to find out."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Investigating Weather Factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x axis: weeks or days\n",
    "#y axis: total count of the week\n",
    "alldays = sorted(unique(APIrecords, 'Date')) #what is this for? not sure if sorting will matter once we have a df."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can access historical high temperatures with NOAA's API:\n",
    "    https://www.ncdc.noaa.gov/cdo-web/webservices/v2#gettingStarted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Accessing Weather Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import NOAA data for daily high temperatures.\n",
    "url_2020 = 'https://www.ncdc.noaa.gov/cdo-web/api/v2/data?datasetid=GHCND&locationid=ZIP:98115&startdate=2020-01-01&enddate=2020-12-31&datatypeid=TMAX&limit=1000' #data response is limited to a one year range so I must break the request into chunks by years.\n",
    "token = \"jMDcJDHzHOqURxuLYjKuoPmwkwNuPyqP\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_2020 = requests.get(url_2020, headers={'token': token})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"value\" here is the temperature, but it's recorded in celsius x10, as if it's missing a decimal point. We'll need to convert that, but for now we can work with it. \n",
    "We'll also need to call each year separately since there is a maximum number of records you can request at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_2020 = 'https://www.ncdc.noaa.gov/cdo-web/api/v2/data?datasetid=GHCND&locationid=ZIP:98115&startdate=2020-01-01&enddate=2020-12-31&datatypeid=TMAX&limit=1000' \n",
    "url_2019 = 'https://www.ncdc.noaa.gov/cdo-web/api/v2/data?datasetid=GHCND&locationid=ZIP:98115&startdate=2019-01-01&enddate=2019-12-31&datatypeid=TMAX&limit=1000' \n",
    "url_2018 = 'https://www.ncdc.noaa.gov/cdo-web/api/v2/data?datasetid=GHCND&locationid=ZIP:98115&startdate=2018-01-01&enddate=2018-12-31&datatypeid=TMAX&limit=1000'\n",
    "url_2017 = 'https://www.ncdc.noaa.gov/cdo-web/api/v2/data?datasetid=GHCND&locationid=ZIP:98115&startdate=2017-01-01&enddate=2017-12-31&datatypeid=TMAX&limit=1000' \n",
    "url_2016 = 'https://www.ncdc.noaa.gov/cdo-web/api/v2/data?datasetid=GHCND&locationid=ZIP:98115&startdate=2016-01-01&enddate=2016-12-31&datatypeid=TMAX&limit=1000' \n",
    "url_2015 = 'https://www.ncdc.noaa.gov/cdo-web/api/v2/data?datasetid=GHCND&locationid=ZIP:98115&startdate=2015-01-01&enddate=2015-12-31&datatypeid=TMAX&limit=1000' \n",
    "url_2014 = 'https://www.ncdc.noaa.gov/cdo-web/api/v2/data?datasetid=GHCND&locationid=ZIP:98115&startdate=2014-01-01&enddate=2014-12-31&datatypeid=TMAX&limit=1000'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_request(url):\n",
    "    token = \"jMDcJDHzHOqURxuLYjKuoPmwkwNuPyqP\"\n",
    "    response = requests.get(url, headers={'token': token})\n",
    "    data = response.json()\n",
    "    results = data['results']\n",
    "    results = pd.DataFrame.from_records(results)\n",
    "    results['Date'] = pd.to_datetime(results['date']).dt.date\n",
    "    results = results.rename(columns={\"date\": \"Timestamp_Date\"}) #dataframe of results\n",
    "    records = results.to_dict('records')\n",
    "    return records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(requests.get(url_2019, headers={'token': 'jMDcJDHzHOqURxuLYjKuoPmwkwNuPyqP'}).content)\n",
    "#this suggests that there is a problem with the API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_2020 = send_request(url_2020)    \n",
    "#weather_2019 = send_request(url_2019)\n",
    "#weather_2018 = send_request(url_2018)\n",
    "#weather_2017 = send_request(url_2017)\n",
    "#weather_2016 = send_request(url_2016)\n",
    "#weather_2015 = send_request(url_2015)\n",
    "#weather_2014 = send_request(url_2014)\n",
    "\n",
    "#nothing before 2020 is working right now, so I am commenting them out in the hopes that it is an API issue that will get fixed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_list=[weather_2020]#, weather_2019, weather_2018, weather_2017, weather_2016, weather_2015, weather_2014]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Preparing Count Data for a Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First I want take the list of dictionaries `APIrecords` and return a single dictionary with date: count as the key: value pair. However, currently each record represents an hour, so I will need to aggregate these into total daily counts first using a new ``dailysum`` function I create below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dailysum(date):\n",
    "    strlist = hourlycounts(date) #produces a list of strings\n",
    "    try: \n",
    "        intlist = list(map(int, strlist)) #converts list to integers\n",
    "    except ValueError: #when data is NaN, give a 0 for that day but shouldn't affect other days\n",
    "        intlist = 0\n",
    "    return sum(intlist) #sums the integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6028"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dailysum('03/20/2020')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next I will utilize the `unique` function I created earlier to generate a unique list of all dates in the dataset which I will then plug into the next function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "alldates = sorted(unique(APIrecords, 'Date')) \n",
    "testdates = alldates[:4] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dates_2020 = sorted(unique(weather_2020, 'Date'))\n",
    "type(dates_2020)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally I create `dict_of_counts` to get my dictionary with date:count as the key:value pair. I test it with the `testdates` list I created above, which is just a subset of the `alldates` list. `alldates` is over 2000 dates so it takes a long time to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{datetime.date(2014, 1, 1): 2190,\n",
       " datetime.date(2014, 1, 2): 1580,\n",
       " datetime.date(2014, 1, 3): 2469,\n",
       " datetime.date(2014, 1, 4): 3337}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def dict_of_counts(datelist):\n",
    "    master_dict = dict()\n",
    "    for date in datelist:\n",
    "        master_dict.update({date: (dailysum(date))})\n",
    "    return master_dict\n",
    "\n",
    "dict_of_counts(testdates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Preparing Weather Data for a Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, that is the counts dictionary. Now I need to work on the high temperatures dictionary. Let's recall what we are working with here. Since `weather_2020` is a list of dictionaries, I can parse it and just call a few items to recall what format it is in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Timestamp_Date': '2020-01-01T00:00:00',\n",
       "  'datatype': 'TMAX',\n",
       "  'station': 'GHCND:USW00094290',\n",
       "  'attributes': ',,W,2400',\n",
       "  'value': 122,\n",
       "  'Date': datetime.date(2020, 1, 1)},\n",
       " {'Timestamp_Date': '2020-01-02T00:00:00',\n",
       "  'datatype': 'TMAX',\n",
       "  'station': 'GHCND:USW00094290',\n",
       "  'attributes': ',,W,2400',\n",
       "  'value': 100,\n",
       "  'Date': datetime.date(2020, 1, 2)},\n",
       " {'Timestamp_Date': '2020-01-03T00:00:00',\n",
       "  'datatype': 'TMAX',\n",
       "  'station': 'GHCND:USW00094290',\n",
       "  'attributes': ',,W,2400',\n",
       "  'value': 150,\n",
       "  'Date': datetime.date(2020, 1, 3)},\n",
       " {'Timestamp_Date': '2020-01-04T00:00:00',\n",
       "  'datatype': 'TMAX',\n",
       "  'station': 'GHCND:USW00094290',\n",
       "  'attributes': ',,W,2400',\n",
       "  'value': 89,\n",
       "  'Date': datetime.date(2020, 1, 4)},\n",
       " {'Timestamp_Date': '2020-01-05T00:00:00',\n",
       "  'datatype': 'TMAX',\n",
       "  'station': 'GHCND:USW00094290',\n",
       "  'attributes': ',,W,2400',\n",
       "  'value': 83,\n",
       "  'Date': datetime.date(2020, 1, 5)}]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_2020[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks promising, but the temperatures are still in the Celsius x 10 format (15.5 degrees Celsius is recorded as 155). When I create our dictionary of date:temperature I need to convert the temperatures to Fahrenheit, and I don't need to be too precise here, so I will round to the nearest degree. I start with a function to do the math:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def convert_temp(oldtemp):\n",
    "    return round(((oldtemp *9/50)+32),0)\n",
    "\n",
    "convert_temp(255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_of_temps(records): #takes a list of dictionaries from NOAA dataset and returns a single dictionary with Date: Temperature as key: value. only one year at a time.\n",
    "    master_dict = dict()\n",
    "    for record in records: #record would be a dictionary containing one date with one temp reading if `records` is a list of dictionaries. \n",
    "        master_dict.update({record['Date']: convert_temp(record['value'])})\n",
    "    return master_dict\n",
    "\n",
    "#dict_of_temps(weather_2020) #right now only 2020 is working because of API issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_temps = dict() #master dictionary of temperatures for all years in dataset.\n",
    "for year in weather_list:\n",
    "    all_temps.update(dict_of_temps(year)) #will this nest the dictionaries? I want them all just combined into one. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dictionary works, and the temperatures look reasonable for their respective times of year. Great! Now I need to create a new dataframe with temperature and count so I can associate each one with the same date and therefore ensure that the temperature and count are matched properly when I do a regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dict_of_counts = dict_of_counts(alldates) #this function takes forever to run. need to change it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##better idea than everything so far\n",
    "create a dataframe with the date as the index and counts and temps each as columns\n",
    "then get the x and y val from the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "#here's one try, but so far it's too slow: creating a dataframe from counts\n",
    "counts_df = pd.DataFrame(dict_of_counts(alldates))\n",
    "counts_df.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df_to_plot = pd.DataFrame()\n",
    "\n",
    "df_to_plot.index = alldates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dates = dates_2020 #can change to alldates once we figure out the API issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-b624b4194fc6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#alternatively, what if we just create a series from each dict?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcounts_series\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict_of_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_dates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mcounts_series\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict_of_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_dates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcounts_series\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-26-2cb2152f55cb>\u001b[0m in \u001b[0;36mdict_of_counts\u001b[0;34m(datelist)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mmaster_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdatelist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mmaster_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mdate\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdailysum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaster_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-24-d4d23f667177>\u001b[0m in \u001b[0;36mdailysum\u001b[0;34m(date)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#when data is NaN, give a 0 for that day but shouldn't affect other days\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mintlist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintlist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#sums the integers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not iterable"
     ]
    }
   ],
   "source": [
    "#alternatively, what if we just create a series from each dict?\n",
    "counts_series = pd.Series(dict_of_counts(current_dates))\n",
    "counts_series.index = dict_of_counts(current_dates).keys()\n",
    "counts_series.head()\n",
    "\n",
    "#TypeError: 'int' object is not iterable. from dailysum function. current_dates is just a list of dates. dailysum(date) is an integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2020-01-01    54.0\n",
       "2020-01-02    50.0\n",
       "2020-01-03    59.0\n",
       "2020-01-04    48.0\n",
       "2020-01-05    47.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_series = pd.Series(dict_of_temps(weather_2020))\n",
    "temp_series.index = dict_of_temps(weather_2020).keys() #when we combine, we will see if these are in the same format as in dict_of_counts\n",
    "temp_series.head()\n",
    "\n",
    "#this one was fast. is dict_of_temps faster for some reason?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict = {'count':counts_series, 'temperature':temp_series}\n",
    "df = pd.DataFrame(df_dict)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "next steps for linear regression:\n",
    "scatterplot of temperature, usage\n",
    "- dataframe to generate x and y values\n",
    "- plot, look for trends, color 2020 differently to spot trends.\n",
    "plot a starting regression line and calculate RSS\n",
    "- see lesson 16, starting on page 7\n",
    "how can I access functions that i've written in other notebooks? \"from _ import _\"\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#code from lesson 16; does this apply?\n",
    "temperature_and_trail_count_trace = #look at trace_values function\n",
    "temp_trail_layout = build_layout(x_range = [0, 300], y_range = [0, 1000]) #look at revenues_layout function and adjust accordingly. \n",
    "\n",
    "from graph import plot #unclear what this means\n",
    "from plotly.offline import iplot, init_notebook_mode\n",
    "init_notebook_mode(connected=True)\n",
    "plot([temperature_and_trail_count_trace], temp_trail_layout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y-values for trace\n",
    "def count_values(datelist): \n",
    "    counts=[]\n",
    "    for date in datelist:\n",
    "        counts.append(dailysum(date)) \n",
    "    return counts\n",
    "\n",
    "count_values(testdates) #does this have count data? it should, because it calls `dailysum()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def temp_values(datelist): #x-values for trace\n",
    "    temps=[]\n",
    "    for date in datelist:\n",
    "        temps.append()\n",
    "    return temps\n",
    "\n",
    "temp_values(alltemps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=__, y=__,\n",
    "                    mode='lines',\n",
    "                    name=''))\n",
    "fig.update_layout(title='Trail Usage as a Function of Temperature',\n",
    "                   xaxis_title='High Temperature (F)',\n",
    "                   yaxis_title='Daily Trail Usage')\n",
    "fig.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
